{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning MNIST\n",
    "\n",
    "In this exercise you will design a classifier for the very simple but very popular [MNIST dataset](http://yann.lecun.com/exdb/mnist/), a classic of dataset in computer vision and one of the first real world problems solved by neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras provides access to a few simple datasets for convenience in the `keras.datasets` module. Here we will load MNIST, a standard benchmark dataset for image classification. This will download the dataset if you have run this code before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a simple dataset of grayscale hand-written digits 28x28 pixels big. So there are 10 classes in the dataset corresponding to the digits 0-9. We can get a sense for what this dataset is like (always a good idea) by looking at some random samples for the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x128bff990>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWBx3R6D7jAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12878ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[np.random.randint(len(X_train))], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a little preprocessing of the dataset. Firstly, we will flatten the 28x28 images to a 784 dimensional vector. This is because our first model below does not care about the spatial dimensions, only the pixel values. The images are represented by numpy arrays of integers between 0 and 255. Since this is a fixed range, we should scale the values down to be from 0 to 1. This normalization simplifies things is usually a good idea, especially since weights are usually initialized randomly near zero.\n",
    "\n",
    "Read the code below and make sure you understand what we are doing to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 'train samples')\n",
      "(10000, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "### Exercise 1 - design an MLP for MNIST\n",
    "\n",
    "Build an MLP. It is up to you what the structure of the model will be, but keep in mind that this problem is much higher dimensional than previous problems we have worked on. This is your first chance to design a model on real data! See if you can get 90% accuracy or better.\n",
    "\n",
    "Here are some of the things you will need to decide about your model:\n",
    "* number of layers\n",
    "* activation function\n",
    "* number of dimensions in each layer\n",
    "* batch size\n",
    "* number of epochs\n",
    "* learning rate\n",
    "\n",
    "Suggestions:\n",
    "* You can pass the argument `verbose=2` to the `model.fit` method to quiet the output a bit, which will speed up the training as well.\n",
    "* You already divided the training and test data, but since you will be trying a series of experiments and changing your model, it is good practice to set aside a **validation** dataset for you to use to track your model improvements. You should only use the test data after you believe you have a good model to evaluate the final performance. Keras can create a validation set for you if you pass the `validation_split=0.1` argument to `model.fit` to tell Keras to hold out 10% of the training data to use as validation.\n",
    "* You can use the `plot_loss` if you find it useful in setting your learning rate etc. during your experiments.\n",
    "* You can refer to previous notebooks and the [documentation](http://keras.io/models/sequential/).\n",
    "\n",
    "If you want to talk over design decisions, feel free to ask!\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_loss(hist):\n",
    "    loss = hist.history['loss']\n",
    "    plt.plot(range(len(loss)), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 36000 samples\n",
      "Epoch 1/10\n",
      "62s - loss: 0.4406 - acc: 0.8752 - val_loss: 0.1954 - val_acc: 0.9478\n",
      "Epoch 2/10\n",
      "60s - loss: 0.2171 - acc: 0.9420 - val_loss: 0.1741 - val_acc: 0.9556\n",
      "Epoch 3/10\n",
      "61s - loss: 0.1773 - acc: 0.9541 - val_loss: 0.1797 - val_acc: 0.9575\n",
      "Epoch 4/10\n",
      "64s - loss: 0.1447 - acc: 0.9624 - val_loss: 0.1728 - val_acc: 0.9590\n",
      "Epoch 5/10\n",
      "61s - loss: 0.1273 - acc: 0.9659 - val_loss: 0.1784 - val_acc: 0.9603\n",
      "Epoch 6/10\n",
      "64s - loss: 0.1166 - acc: 0.9694 - val_loss: 0.1775 - val_acc: 0.9614\n",
      "Epoch 7/10\n",
      "60s - loss: 0.1009 - acc: 0.9727 - val_loss: 0.1515 - val_acc: 0.9685\n",
      "Epoch 8/10\n",
      "62s - loss: 0.0962 - acc: 0.9738 - val_loss: 0.1654 - val_acc: 0.9646\n",
      "Epoch 9/10\n",
      "59s - loss: 0.0826 - acc: 0.9773 - val_loss: 0.1831 - val_acc: 0.9651\n",
      "Epoch 10/10\n",
      "62s - loss: 0.0773 - acc: 0.9781 - val_loss: 0.1670 - val_acc: 0.9691\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_54 (Dense)                 (None, 784)           615440      dense_input_19[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, 784)           0           dense_54[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 784)           0           activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_55 (Dense)                 (None, 49)            38465       dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 49)            0           dense_55[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, 49)            0           dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_56 (Dense)                 (None, 24)            1200        activation_54[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 24)            0           dense_56[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, 24)            0           dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_57 (Dense)                 (None, 10)            250         activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, 10)            0           dense_57[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 655,355\n",
      "Trainable params: 655,355\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Build the rest of you model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(784, input_dim=784)) # Change the hidden layer to be 3 dimensional\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(784/16))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(784/32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "# Add a 'relu' layer and Dense layer with an output of 2 dimensions\n",
    "model.add(Activation('softmax'))\n",
    "sgd = SGD(lr=0.01)\n",
    "adam = Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "               optimizer=adam,\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=10, batch_size=8, verbose=2, validation_split=0.6)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test score:', 0.14430141886289058)\n",
      "('Test accuracy:', 0.97219999999999995)\n"
     ]
    }
   ],
   "source": [
    "# Final test evaluation\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
