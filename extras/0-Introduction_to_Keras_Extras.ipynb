{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Keras: Extras\n",
    "\n",
    "The \"blobs\" dataset is a very easy one, but we can learn important things from easy datasets. Below we explore how to make the dataset a bit harder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `make_blobs` function has a handful of useful inputs:\n",
    "* `n_samples` determines the number of points\n",
    "* `centers` is a list of coordinates for each of the classes\n",
    "* `cluster_std` is the standard deviation around the centers used to randomly generate the data\n",
    "* `n_features` is the dimension of the data points\n",
    "\n",
    "Here is what we used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(n_samples=1000,\n",
    "                  centers=[[0.1, 0.1],[0.9, 0.9]],\n",
    "                  cluster_std=0.3,\n",
    "                  n_features=2)\n",
    "\n",
    "y = np_utils.to_categorical(y)\n",
    "plt.scatter(X[:,0], X[:,1], c=y[:,0], alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "### Exercise 1\n",
    "\n",
    "Try changing the `centers` and `cluster_std` below to make the dataset harder or easier. What does \"harder\" mean in this context?\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the dataset \"harder\" and plot it\n",
    "X, y = make_blobs(n_samples=1000,\n",
    "                  centers=[[0.1, 0.1],[0.9, 0.9]],\n",
    "                  cluster_std=0.3,\n",
    "                  n_features=2)\n",
    "\n",
    "y = np_utils.to_categorical(y)\n",
    "plt.scatter(X[:,0], X[:,1], c=y[:,0], alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "### Exercise 2\n",
    "\n",
    "Build a Keras model and train it on a few different versions of the dataset, both really easy and really hard versions. The decision boundary function is copies below for you to visualize the model's solutions.\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    X_max = X.max(axis=0)\n",
    "    X_min = X.min(axis=0)\n",
    "    xticks = np.linspace(X_min[0], X_max[0], 100)\n",
    "    yticks = np.linspace(X_min[1], X_max[1], 100)\n",
    "    xx, yy = np.meshgrid(xticks,\n",
    "                         yticks)\n",
    "    ZZ = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = ZZ[:,0] >= 0.5\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = plt.gca()\n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.bwr, alpha=0.2)\n",
    "    ax.scatter(X[:,0], X[:,1], c=y[:,0], alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.04),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, nb_epoch=20, batch_size=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
