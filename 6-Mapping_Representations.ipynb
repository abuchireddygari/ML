{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Representations\n",
    "\n",
    "Recall that we can think of a deep model learning as series of new \"representations\" at each layer of its processing, each representation making the overall solution that the network is trying to achieve easier. We can understand what the information the representations at each layer captures by mapping the representations in a 2-dimensional scatter plot that we can inspect.\n",
    "\n",
    "Let's start by loading MNIST and a trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import offsetbox\n",
    "from keras.datasets import mnist\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the MNIST model we trained beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load model structure\n",
    "model = model_from_json(open('mnist_cnn.json').read())\n",
    "\n",
    "# Load model weights\n",
    "model.load_weights('mnist_cnn_weights.h5')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping data with tSNE\n",
    "\n",
    "[tSNE](https://lvdmaaten.github.io/tsne/) is a commonly used visualization tool in deep learning. It is a dimensionality reduction technique: it takes high-dimensional data and maps them into a 2-dimensional space such that the relationships of the data is preserved. We call this low-dimensional mapping an \"embedding\".\n",
    "\n",
    "Below is a function that creates a plot of an embedding. We will soon see what it looks like and how to interpret it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adapted from http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
    "\n",
    "def plot_embedding(imgs, X, y, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    # Plot colors numbers\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        # plot colored number\n",
    "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    # Add image overlays\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = np.array([[1., 1.]])  # just something big\n",
    "        for i in range(X.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(imgs[i], cmap=plt.cm.gray_r), X[i])\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tSNE takes a list of representations for each example data as input and outputs a 2-d location for that example. Below, we do this to the input data itself and plot the result. Read and run the steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the data to embed - in this case the first 1000 training examples\n",
    "# We reshape the data from its 28x28 size to a flat vector\n",
    "num_emb = 1000\n",
    "reps = X_train[:num_emb].reshape([num_emb, 28*28])\n",
    "print reps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit our tSNE mapping to the `reps` data vectors\n",
    "tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=3000, method='exact')\n",
    "emb = tsne.fit_transform(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To make the plot, we input the image data itself, the embedding data we fit with tSNE,\n",
    "# and class labels for the the data points\n",
    "num_plot = 500\n",
    "plot_embedding(np.squeeze(X_train[:num_plot]), emb[:num_plot], y_train[:num_plot])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "### Exercise 1 - interpreting a tSNE plot\n",
    "\n",
    "Inspect the plot of the raw input data. What do you observe?\n",
    "\n",
    "tSNE tries to preserve the distances of the data: if points are close to each other in the representation, tSNE tries to keep them close to each other in the embedding.\n",
    "\n",
    "How do you think this plot might look different if the numbers in our dataset were not centered in the image? Why?\n",
    "- - -\n",
    "\n",
    "## Visualizing deep representations\n",
    "\n",
    "We will now do the same as we did above, but instead of using the raw input data as our representation, we will use the hidden layer activations of your model as the representation.\n",
    "\n",
    "Here are the layers we can choose to visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function we can use to extract layer outputs. Right now it extracts activations from the first layer. More information on this feature of Keras can be found [here](http://keras.io/getting-started/faq/#how-can-i-visualize-the-output-of-an-intermediate-layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_layer = K.function([model.layers[0].input, K.learning_phase()], [model.layers[1].output])\n",
    "reps = get_layer([X_train[:num_emb], 0])[0]\n",
    "print reps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "### Exercise 2 - map a deep layer\n",
    "\n",
    "Below, change the layer function to extract the output for a fully-connected layer deep in your network. Create a tSNE embedding with this layer and plot it.\n",
    "\n",
    "What do you observe?\n",
    "1. Characterize the difference between this plot and the last plot.\n",
    "2. Can you find any \"mistakes\" in this plot?\n",
    "3. You might notice clusters of data. Do the relationship between these clusters in the plot seem sensible to you? Can you explain this?\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a tSNE plot with a deep fully-connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "### Bonus Exercise 3 - map a middle layer\n",
    "\n",
    "Choose another layer in your model and map it as above. You can choose another \"flat layer\" if your model has one, or you can choose a convolutional layer (in fact, it is interesting to try both). If you choose a convolutional layer, remember you will need to reshape the representations so that they are flat before doing tSNE.\n",
    "\n",
    "Compared to earlier plots, is there a noticeable difference? Can you explain the relationship among all of the plots we have made?\n",
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map another hidden layer lower in the network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
